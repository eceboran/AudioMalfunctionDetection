{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bff5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.insert(0, \"..\\\\..\\\\\")  # add the parent directory to path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from utils.get_mel_spectrogram import get_mel_spectrogram\n",
    "from utils.get_melspec_features_from_files import get_melspec_features_from_files\n",
    "from utils.confusion_metrics import confusion_metrics\n",
    "from utils.train_test_one_class_svm import train_test_one_class_svm\n",
    "from utils.get_train_test_data import get_train_test_data\n",
    "from utils.add_train_test_labels_to_dataframe import add_train_test_labels_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f320dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "parent_dir = os.path.abspath('..\\\\..\\\\..\\\\')  # main directory\n",
    "# Audio data directory\n",
    "data_dir = os.path.join(parent_dir, 'Data', 'Source')  # audio data directory\n",
    "# Features directory\n",
    "features_dir = os.path.join(parent_dir, 'Data', 'Features')  # audio data directory\n",
    "# Metada directory\n",
    "metadata_dir = os.path.join(parent_dir, 'Data', 'Metadata')  # metadata directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d9e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted features\n",
    "machine_type = 'fan'\n",
    "\n",
    "window = 1\n",
    "n_mels = 32\n",
    "overlap = 0.5\n",
    "feature_type = 'mel_spect_db'\n",
    "    \n",
    "# Export the metadata and extracted features DataFrames to csv files\n",
    "file_name = f\"metadata_{machine_type}_all_samples.csv\"\n",
    "df_machine = pd.read_csv(os.path.join(features_dir, file_name), header=0, index_col=0)\n",
    "\n",
    "file_name = f\"features_{machine_type}_{feature_type}_window_{window:.3f}_overlap_ratio_{overlap:.2f}_no_mel_bands_{n_mels:d}.csv\"\n",
    "Xy = pd.read_csv(os.path.join(features_dir, file_name), header=0, index_col=0)\n",
    "\n",
    "# Load params \n",
    "file_name = f\"params_{machine_type}_{feature_type}_window_{window:.3f}_overlap_ratio_{overlap:.2f}_no_mel_bands_{n_mels:d}.json\"\n",
    "with open(os.path.join(features_dir, file_name)) as json_file:\n",
    "    params = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a848232f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10868/893573266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Randomly select a subset of samples for a single machine and a single model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmachine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fan'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_machine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachine\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'fan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_model_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_machine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_machine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Randomly select a subset of samples for a single machine and a single model\n",
    "machine = 'fan'\n",
    "df_machine = df[df.machine=='fan']\n",
    "df_model_all = df_machine[df_machine.model==0]\n",
    "\n",
    "df_model = df_model_all.groupby([\"anomaly\"]).sample(frac=0.8, random_state=13)\n",
    "df_model_test = df_model_all.drop(df_model.index)\n",
    "df_model = df_model.reset_index(inplace=False, drop=False)\n",
    "df_model = df_model.sample(frac=1, random_state=25).reset_index(inplace=False, drop=True)  # shuffle data\n",
    "df_model_test = df_model_test.reset_index(inplace=False, drop=False)\n",
    "\n",
    "df_model.groupby([\"model\", \"anomaly\"])['file_name'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f828ce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Randomly separate a subset of samples as the final test samples\n",
    "df_machine_all = df_machine.copy()\n",
    "\n",
    "df_machine = df_machine.groupby([\"anomaly\"]).sample(frac=0.8, random_state=13)\n",
    "df_machine_test = df_machine_all.drop(df_machine.index)\n",
    "\n",
    "Xy_all = Xy.copy()\n",
    "Xy = Xy.loc[df_machine.index]\n",
    "Xy_test = Xy_all.loc[df_machine_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine = df_machine.reset_index(inplace=False, drop=False)\n",
    "df_machine_test = df_machine_test.reset_index(inplace=False, drop=False)\n",
    "Xy = Xy.reset_index(inplace=False, drop=False)\n",
    "Xy_test = Xy_test.reset_index(inplace=False, drop=False)\n",
    "\n",
    "df_machine.groupby([\"model\", \"anomaly\"])['file_name'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0addec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.iloc[:, :-1]\n",
    "X = X.copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293d641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = Xy.iloc[:, -1]\n",
    "y = pd.DataFrame(y.copy())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39249823",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa312296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature normalization\n",
    "minval = X.min()\n",
    "maxval = X.max()\n",
    "X = (X-minval)/(maxval-minval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a178d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae165d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77622a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95a181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a619dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels for training and test\n",
    "df_machine = add_train_test_labels_to_dataframe(df_machine, no_seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test samples\n",
    "X_train, X_test, y_train, y_test = get_train_test_data(X, y, df_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c490a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of features\n",
    "plt.hist(X_train.iloc[:, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One class svm \n",
    "gamma = 0.01\n",
    "nu = 0.5\n",
    "prctle = 2\n",
    "out_class = train_test_one_class_svm(X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy(), \n",
    "                                     kernel='rbf', gamma=gamma, nu=nu, prctle=prctle, normalize=\"min-max\")\n",
    "# return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot = out_class[3]\n",
    "df_cm = pd.DataFrame(cm_plot, range(cm_plot.shape[0]), range(cm_plot.shape[1]))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(out_class[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c72c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ran_gamma = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "ran_prctl = range(1,15)\n",
    "nu = 0.5\n",
    "# Initialize arrays\n",
    "out_metrics_gn = {}\n",
    "out_metrics_gn['acc'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_gn['precision']  = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_gn['recall'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_gn['TPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_gn['FPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "for id_g, gamma in enumerate(ran_gamma):\n",
    "    for id_p, prctle in enumerate(ran_prctl):\n",
    "        print(gamma, prctle)\n",
    "        \n",
    "        out_class = train_test_one_class_svm(X_train, X_test, y_train, y_test, \n",
    "                                     kernel='rbf', gamma=gamma, nu=nu, prctle=prctle, normalize=\"min-max\")\n",
    "        # return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params\n",
    "        \n",
    "        out_metrics = out_class[5]\n",
    "        out_metrics_gn['acc'][id_p, id_g] = out_metrics['acc']\n",
    "        out_metrics_gn['precision'][id_p, id_g] = out_metrics['precision']\n",
    "        out_metrics_gn['recall'][id_p, id_g] = out_metrics['recall']\n",
    "        out_metrics_gn['TPR'][id_p, id_g] = out_metrics['TPR']\n",
    "        out_metrics_gn['FPR'][id_p, id_g] = out_metrics['FPR']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb13aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ran_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53700cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_metrics_gn['recall'][:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e94dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metrics_gn['precision'][:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227efc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metrics_gn['recall'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_g, gamma in enumerate(ran_gamma):\n",
    "    if(id_g<8):\n",
    "        plt.plot(out_metrics_gn['recall'][:, id_g], out_metrics_gn['precision'][:, id_g])\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cf9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_g, gamma in enumerate(ran_gamma):\n",
    "    if(id_g==5):\n",
    "        print(gamma)\n",
    "        plt.plot(out_metrics_gn['recall'][:, id_g], out_metrics_gn['precision'][:, id_g])\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b98195",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metrics_gn['precision'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaa20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_p = 12\n",
    "id_g = 5\n",
    "print(ran_prctl[id_p])\n",
    "print(\"precision: \", out_metrics_gn['precision'][id_p, id_g])\n",
    "print(\"recall: \", out_metrics_gn['recall'][id_p, id_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92401f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select all abnormal samples as test, equal number of normal also in test, rest in training\n",
    "df_machine_all = df[df.machine=='fan']\n",
    "\n",
    "window = 0.5\n",
    "n_mels = 64\n",
    "overlap = 0.25\n",
    "\n",
    "X_all, y_all, params_all = get_melspec_features_from_files(data_dir, df_machine_all, window, n_mels, overlap)\n",
    "\n",
    "# Add labels for training and test\n",
    "df_machine_all = add_train_test_labels_to_dataframe(df_machine_all, no_seed=30)\n",
    "\n",
    "# Get training and test samples\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = get_train_test_data(X_all, y_all, df_machine_all)\n",
    "\n",
    "# One class svm \n",
    "id_p = 12\n",
    "id_g = 5\n",
    "prctl = ran_prctl[id_p]\n",
    "gamma = ran_gamma[id_g]\n",
    "nu = 0.5\n",
    "out_class_selected = train_test_one_class_svm(X_train, X_test, y_train, y_test, \n",
    "                                     kernel='rbf', gamma=gamma, nu=nu, prctle=prctle, normalize=\"min-max\")\n",
    "# return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_g_selected = 5\n",
    "ran_gamma_selected = [ran_gamma[id_g_selected]]\n",
    "nu = 0.5\n",
    "# Initialize arrays\n",
    "out_metrics_all_gn = {}\n",
    "out_metrics_all_gn['acc'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['precision']  = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['recall'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['TPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['FPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "for id_g, gamma in enumerate(ran_gamma_selected):\n",
    "    for id_p, prctle in enumerate(ran_prctl):\n",
    "        \n",
    "        out_class = train_test_one_class_svm(X_train_all, X_test_all, y_train_all, y_test_all, \n",
    "                                     kernel='rbf', gamma=0.001, nu=0.5, prctle=2, normalize=\"min-max\")\n",
    "        # return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params\n",
    "        \n",
    "        out_metrics = out_class[5]\n",
    "        out_metrics_all_gn['acc'][id_p, id_g] = out_metrics['acc']\n",
    "        out_metrics_all_gn['precision'][id_p, id_g] = out_metrics['precision']\n",
    "        out_metrics_all_gn['recall'][id_p, id_g] = out_metrics['recall']\n",
    "        out_metrics_all_gn['TPR'][id_p, id_g] = out_metrics['TPR']\n",
    "        out_metrics_all_gn['FPR'][id_p, id_g] = out_metrics['FPR']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_gamma = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "ran_prctl_selected = 7 # range(0,15)\n",
    "nu = 0.5\n",
    "# Initialize arrays\n",
    "out_metrics_all_gn = {}\n",
    "out_metrics_all_gn['acc'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['precision']  = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['recall'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['TPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "out_metrics_all_gn['FPR'] = np.zeros((len(ran_prctl), len(ran_gamma)))\n",
    "for id_g, gamma in enumerate(ran_gamma):\n",
    "    for id_p, prctle in enumerate(ran_prctl_selected):\n",
    "        \n",
    "        out_class = train_test_one_class_svm(X_train_all, X_test_all, y_train_all, y_test_all, \n",
    "                                     kernel='rbf', gamma=0.001, nu=0.5, prctle=2, normalize=\"min-max\")\n",
    "        # return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params\n",
    "        \n",
    "        out_metrics = out_class[5]\n",
    "        out_metrics_all_gn['acc'][id_p, id_g] = out_metrics['acc']\n",
    "        out_metrics_all_gn['precision'][id_p, id_g] = out_metrics['precision']\n",
    "        out_metrics_all_gn['recall'][id_p, id_g] = out_metrics['recall']\n",
    "        out_metrics_all_gn['TPR'][id_p, id_g] = out_metrics['TPR']\n",
    "        out_metrics_all_gn['FPR'][id_p, id_g] = out_metrics['FPR']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_g, gamma in enumerate(ran_gamma):\n",
    "    for id_p, prctle in enumerate(ran_prctl_selected):\n",
    "        if(id_g==id_g_selected):\n",
    "            print(gamma)\n",
    "            plt.plot(out_metrics_all_gn['recall'][:, id_g], out_metrics_all_gn['precision'][:, id_g])\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the previously chosen gamma and prctle\n",
    "id_p_selected = 3\n",
    "prctl = ran_prctle[id_p_selected]\n",
    "gamma = ran_gamma[id_g_selected]\n",
    "out_class = train_test_one_class_svm(X_train_all, X_test_all, y_train_all, y_test_all, \n",
    "                                     kernel='rbf', gamma=gamma, nu=nu, prctle=prctle, normalize=\"min-max\")\n",
    "# return OneClassSVM, report, cm_train, cm_test, out_metrics_train, out_metrics_test, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed96d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metrics_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d831393",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metrics_train_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
